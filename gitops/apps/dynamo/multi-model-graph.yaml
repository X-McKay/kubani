---
# Single-model DynamoGraphDeployment with gpt-oss-20b
# Pinned to sparky node (DGX Spark)
apiVersion: nvidia.com/v1alpha1
kind: DynamoGraphDeployment
metadata:
  name: multi-model
  namespace: dynamo
spec:
  # Global environment variables for KV-cache-aware routing
  envs:
    - name: DYN_ROUTER_MODE
      value: "kv"
  services:
    # Frontend with KV-cache-aware routing
    Frontend:
      envFromSecret: hf-token-secret
      dynamoNamespace: multi-model
      componentType: frontend
      replicas: 1
      extraPodSpec:
        mainContainer:
          image: nvcr.io/nvidia/ai-dynamo/vllm-runtime:0.7.0

    # GPT-OSS-20B - 20B MoE model
    GptOssWorker:
      envFromSecret: hf-token-secret
      dynamoNamespace: multi-model
      componentType: worker
      replicas: 1
      resources:
        limits:
          gpu: "1"
      extraPodSpec:
        runtimeClassName: nvidia
        nodeSelector:
          kubernetes.io/hostname: sparky
        volumes:
          - name: model-cache
            persistentVolumeClaim:
              claimName: model-storage
        mainContainer:
          image: nvcr.io/nvidia/ai-dynamo/vllm-runtime:0.7.0
          workingDir: /workspace/examples/backends/vllm
          volumeMounts:
            - name: model-cache
              mountPath: /home/dynamo/.cache/huggingface
          command:
            - python3
            - -m
            - dynamo.vllm
          args:
            - --model
            - openai/gpt-oss-20b
            - --served-model-name
            - openai/gpt-oss-20b
            - --quantization
            - fp8
            - --gpu-memory-utilization
            - "0.4"
            - --enforce-eager
