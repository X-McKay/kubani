---
# OpenAI-compatible API frontend
apiVersion: inference.nvidia.com/v1alpha1
kind: InferenceEndpoint
metadata:
  name: openai-api
  namespace: dynamo
spec:
  # Backend reference
  backendRef:
    name: gpt-oss-20b
    kind: VLLMBackend

  # API configuration
  api:
    type: openai
    port: 8000

  # Service configuration
  service:
    type: ClusterIP
    port: 8000
---
# Ingress for OpenAI API endpoint
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: openai-api
  namespace: dynamo
  annotations:
    cert-manager.io/cluster-issuer: "letsencrypt-production"
spec:
  ingressClassName: traefik
  tls:
    - hosts:
        - llm.almckay.io
      secretName: llm-tls
  rules:
    - host: llm.almckay.io
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: openai-api
                port:
                  number: 8000
