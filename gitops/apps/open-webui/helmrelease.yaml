apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: open-webui
  namespace: open-webui
spec:
  interval: 10m
  chart:
    spec:
      chart: open-webui
      version: "5.20.0"
      sourceRef:
        kind: HelmRepository
        name: open-webui
        namespace: flux-system
  install:
    remediation:
      retries: 3
  upgrade:
    remediation:
      retries: 3
  values:
    # Disable built-in Ollama (we use external LLM endpoint)
    ollama:
      enabled: false

    # Disable pipelines
    pipelines:
      enabled: false

    # Persistence for chat history
    persistence:
      enabled: true
      size: 5Gi

    # OpenAI API configuration
    openaiBaseApiUrl: "https://llm.almckay.io/v1"

    # Extra environment variables from secret
    extraEnvVars:
      - name: OAUTH_CLIENT_ID
        valueFrom:
          secretKeyRef:
            name: open-webui-credentials
            key: oauth-client-id
      - name: OAUTH_CLIENT_SECRET
        valueFrom:
          secretKeyRef:
            name: open-webui-credentials
            key: oauth-client-secret
      - name: OPENAI_API_KEY
        valueFrom:
          secretKeyRef:
            name: open-webui-credentials
            key: openai-api-key
      - name: OAUTH_PROVIDER_NAME
        value: "authentik"
      - name: OPENID_PROVIDER_URL
        value: "https://auth.almckay.io/application/o/open-webui/.well-known/openid-configuration"
      - name: OPENID_REDIRECT_URI
        value: "https://chat.almckay.io/oauth/oidc/callback"
      - name: WEBUI_URL
        value: "https://chat.almckay.io"
      - name: ENABLE_OAUTH_SIGNUP
        value: "true"
      - name: ENABLE_LOGIN_FORM
        value: "false"
      - name: OAUTH_MERGE_ACCOUNTS_BY_EMAIL
        value: "true"
      - name: DEFAULT_MODELS
        value: "Qwen/Qwen3-0.6B"
      - name: DEFAULT_USER_ROLE
        value: "user"
      - name: ENABLE_OAUTH_ROLE_MANAGEMENT
        value: "true"
      - name: ENABLE_OPENAI_API
        value: "true"
